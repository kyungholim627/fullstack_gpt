{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlaru\\AppData\\Local\\Temp\\ipykernel_24536\\17558250.py:8: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n",
      "c:\\Users\\dlaru\\OneDrive\\바탕 화면\\fullstack_gpt\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the meaning of potato?\\n\\nPotato is a starchy tuber that is a staple food in many parts of the world. It is native to South America and was first domesticated by the indigenous peoples of the Andes region around 7000 BC. Potatoes are grown from tubers, which are underground modified stems, and they come in a variety of shapes, sizes, and colors. They are a good source of carbohydrates, fiber, vitamin C, and potassium. Potatoes can be cooked in a variety of ways, including boiling, baking, frying, and mashing. They are a versatile ingredient and can be used in a wide range of dishes, from soups and stews to salads and casseroles.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using models via HuggingFace\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"What is the meaning of {word}\"\n",
    ")\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "model_kwargs={\n",
    "\"max_new_tokens\": 250\n",
    "}\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\":\"potato\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlaru\\OneDrive\\바탕 화면\\fullstack_gpt\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dlaru\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A potatois a plant whose roots are of different kinds, so they can be distinguished. But they have been found in the soil in the course of a very long time. And they are not found in the same plant but in the same genus. They have the same'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading models via HuggingFace\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"A {word}is a\"\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id = \"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\":50\n",
    "    }\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\":\"potato\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
